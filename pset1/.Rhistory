temp<-NULL
temp1<-NULL
temp2<-NULL
}
print('n1')
print(i)
save.image("E:/bigdata intern/data/Fangtianxia/1.RData")
Sys.sleep(100)
}
save.image("E:/bigdata intern/data/Fangtianxia/203.RData")
for(i in 203:n1){
x1=121.100+x_step*(i-1)
x2=x1+x_step1
print('n1')
print(i)
for(j in 1:n2){
y1=30.500+y_step*(j-1)
y2=y1+y_step1
print(j)
api<-paste(bld_api1, x1, "&y1=", y1,  "&x2=", x2,  "&y2=", y2, bld_api2, sep="")
try(test<-getURI(api, encoding="UTF-8"))
try(temp<-fromJSON(test))
if(length(temp)>2){
if(length(temp$loupan)>0){
temp1<-as.data.frame(temp$loupan, stringsAsFactors=F)
proj_list<-rbind(proj_list, temp1)
print('proj_list updated')
}
if(length(temp$ecshop)>0){
temp2<-as.data.frame(temp$ecshop, stringsAsFactors=F)
ecshop_list<-rbind(ecshop_list, temp2)
print('ecshop_list updated')
}
}
temp<-NULL
temp1<-NULL
temp2<-NULL
}
print('n1')
print(i)
save.image("E:/bigdata intern/data/Fangtianxia/1.RData")
Sys.sleep(100)
}
save.image("E:/bigdata intern/data/Fangtianxia/290.RData")
View(proj_list)
write.csv('290.RData', file="D:/bearf2.csv")
write.csv(proj_list, file="D:/bearf2.csv")
library(XML)
library(rvest)
library(RCurl)
library(XML)
Sys.setlocale("LC_CTYPE", "chs")
store_url<-c("http://www.dianping.com/shop/19662767", "http://www.dianping.com/shop/23678724", "http://www.dianping.com/shop/13767007", "http://www.dianping.com/shop/4507741")
store_review<-NULL
for(i in 1:length(store_url)){
print(i)
temp<-try(getURI(paste(store_url[i], "/review_more", sep="")))
temp1<-strsplit(temp, "\n")[[1]]
page_n<- temp1[grep('class=\"PageLink\"', temp1)]
page_n<- sapply(page_n, function(x)strsplit(x, ">|<")[[1]][3])
page_n<- max(as.numeric(page_n))
lines<-grep('title="" href="/member/', temp1)
member_id<-temp1[grep('title="" href="/member/', temp1)]
member_id<- sapply(member_id, function(x)strsplit(x, 'member/|">')[[1]][3])
lines<-grep(' <span class="rst">口味', temp1)
taste_score<-sapply(temp1[lines], function(x)strsplit(x, '<|>')[[1]][3])
envir_score<-sapply(temp1[lines+1], function(x)strsplit(x, '<|>')[[1]][3])
service_score<-sapply(temp1[lines+2], function(x)strsplit(x, '<|>')[[1]][3])
reviews<-temp1[grep('<div class="J_brief-cont">', temp1)+1]
store_review_temp<-cbind(member_id, taste_score, envir_score, service_score, reviews)
store_review_temp$store_id<-gsub("http://www.dianping.com/shop/", "", store_url)
store_review<-rbind(store_review, store_review_temp)
for(j in 2:page_n){
temp<-try(getURL(paste(store_url[i], "/review_more?pageno=", j, sep="")))
temp1<-strsplit(temp, "\n")[[1]]
page_n<- temp1[grep('class=\"PageLink\"', temp1)]
page_n<- sapply(page_n, function(x)strsplit(x, ">|<")[[1]][3])
page_n<- max(as.numeric(page_n))
lines<-grep('title="" href="/member/', temp1)
member_id<-temp1[grep('title="" href="/member/', temp1)]
member_id<- sapply(member_id, function(x)strsplit(x, 'member/|">')[[1]][3])
lines<-grep(' <span class="rst">口味', temp1)
taste_score<-sapply(temp1[lines], function(x)strsplit(x, '<|>')[[1]][3])
envir_score<-sapply(temp1[lines+1], function(x)strsplit(x, '<|>')[[1]][3])
service_score<-sapply(temp1[lines+2], function(x)strsplit(x, '<|>')[[1]][3])
reviews<-temp1[grep('<div class="J_brief-cont">', temp1)+1]
store_review_temp<-cbind(member_id, taste_score, envir_score, service_score, reviews)
store_review_temp$store_id<-gsub("http://www.dianping.com/shop/", "", store_url)
store_review<-rbind(store_review, store_review_temp)
}
}
warnings()
63+78
0.9*0.1*0.01
0.1/(9e-04)
0.5*0.09*0.1
0.5*0.99*0.1
0.0495+0.0009
0.1*0.99*0.9
0.5*0.99*0.1
0.6*0.01*0.9
0.54+0.09
0.1*0.9/0.63
0.5*0.99*0.1/(0.5*0.99*0.1+0.1*0.99*0.1)
0.5*0.1*0.99 + 0.9*0.1*0.01 + 0.6*0.01*0.09 + 0.1*0.99*0.9
0.5*0.1*0.99 + 0.9*0.1*0.01
0.0504/0.1404
0.0504/0.14004
0.05/0.14
p1=0.01
p0=1-p1
a1=0.1
a0 = 1-a1
d = 0.1*p0*a0 + 0.5*p0*a1 + 0.6*p1*a0 + 0.9*p1*a1
d
n =  0.5*p0*a1 + 0.9*p1*a1
n/d
file = read.csv(file="c:/Users/Theop/Desktop/数据/通卡公司--刷卡数据/Cqic201608_201707", header=TRUE, sep=",")
a= "C:/Users/Theop/Desktop/DATA/card/cqic201608_201707/cqic201608.csv"
file = read.csv(a,header=TRUE, sep=",")
a= "C:/Users/Theop/Desktop/DATA/card/cqic201608_201707/cqic201608_201707.csv"
file = read.csv(a,header=TRUE, sep=",")
load("E:/bigdata intern/data/GUANGZHOU/1.RData")
library(RCurl)
library(jsonlite)
Sys.setlocale("LC_CTYPE", "chs")
for(i in 520:n1){
x1=112.9436+x_step*(i-1)
x2=x1+x_step1
print('n1')
print(i)
for(j in 1:n2){
y1=22.5669+y_step*(j-1)
y2=y1+y_step1
print(j)
api<-paste(bld_api1, x1, "&y1=", y1,  "&x2=", x2,  "&y2=", y2, bld_api2, sep="")
try(test<-getURI(api, encoding="UTF-8"))
try(temp<-fromJSON(test))
if(length(temp)>2){
if(length(temp$loupan)>0){
temp1<-as.data.frame(temp$loupan, stringsAsFactors=F)
proj_list<-rbind(proj_list, temp1)
print('proj_list updated')
}
if(length(temp$ecshop)>0){
temp2<-as.data.frame(temp$ecshop, stringsAsFactors=F)
ecshop_list<-rbind(ecshop_list, temp2)
print('ecshop_list updated')
}
}
temp<-NULL
temp1<-NULL
temp2<-NULL
}
print('n1')
print(i)
save.image("E:/bigdata intern/data/GUANGZHOU/1.RData")
Sys.sleep(100)
}
for(i in 547:n1){
x1=112.9436+x_step*(i-1)
x2=x1+x_step1
print('n1')
print(i)
for(j in 1:n2){
y1=22.5669+y_step*(j-1)
y2=y1+y_step1
print(j)
api<-paste(bld_api1, x1, "&y1=", y1,  "&x2=", x2,  "&y2=", y2, bld_api2, sep="")
try(test<-getURI(api, encoding="UTF-8"))
try(temp<-fromJSON(test))
if(length(temp)>2){
if(length(temp$loupan)>0){
temp1<-as.data.frame(temp$loupan, stringsAsFactors=F)
proj_list<-rbind(proj_list, temp1)
print('proj_list updated')
}
if(length(temp$ecshop)>0){
temp2<-as.data.frame(temp$ecshop, stringsAsFactors=F)
ecshop_list<-rbind(ecshop_list, temp2)
print('ecshop_list updated')
}
}
temp<-NULL
temp1<-NULL
temp2<-NULL
}
print('n1')
print(i)
save.image("E:/bigdata intern/data/GUANGZHOU/1.RData")
Sys.sleep(100)
}
for(i in 559:n1){
x1=112.9436+x_step*(i-1)
x2=x1+x_step1
print('n1')
print(i)
for(j in 1:n2){
y1=22.5669+y_step*(j-1)
y2=y1+y_step1
print(j)
api<-paste(bld_api1, x1, "&y1=", y1,  "&x2=", x2,  "&y2=", y2, bld_api2, sep="")
try(test<-getURI(api, encoding="UTF-8"))
try(temp<-fromJSON(test))
if(length(temp)>2){
if(length(temp$loupan)>0){
temp1<-as.data.frame(temp$loupan, stringsAsFactors=F)
proj_list<-rbind(proj_list, temp1)
print('proj_list updated')
}
if(length(temp$ecshop)>0){
temp2<-as.data.frame(temp$ecshop, stringsAsFactors=F)
ecshop_list<-rbind(ecshop_list, temp2)
print('ecshop_list updated')
}
}
temp<-NULL
temp1<-NULL
temp2<-NULL
}
print('n1')
print(i)
save.image("E:/bigdata intern/data/GUANGZHOU/1.RData")
Sys.sleep(100)
}
n1
x_step<-0.0019
y_step<-0.0019
x_step1<-0.048
y_step1<-0.01
n1<-ceiling((114.0026-112.9436)/x_step)
n1
save.image("E:/bigdata intern/data/GUANGZHOU/final.RData")
View(proj_list)
117-2931
31+5880
a = c(2808, - 3069)
b = c(13052378, 3740014)
b-a
a = c(117, 31)
b = c(2671-2249)
a-b
b = c(2671,-2249)
a-b
c = c(2551,-1928)
a-c
1983/181
2048/185
2052/185
load("E:/bigdata intern/data/GUANGZHOU/final.RData")
head(proj_list)
View(proj_list)
library(xlsx)
install.packages('xlsx')
library(xlsx)
Sys.setlocale("LC_CTYPE", "chs")
data = read.xlsx("E:/bigdata intern/rent/minyue.xls",sheetName="披露文件",header=T)
data = read.xlsx("E:/bigdata intern/rent/minyue.xls",sheetName="a",header=T)
data = read.xlsx("E:/bigdata intern/rent/minyue.xls",sheetName="a",header=F)
View(data)
library(xlsx)
Sys.setlocale("LC_CTYPE", "chs")
data = read.xlsx("E:/bigdata intern/rent/minyue.xls",sheetName="a",header=F)
View(data)
data = read.xlsx("E:/bigdata intern/rent/minyue.xls",sheetName="a",header=F,encoding="UTF-8")
View(data)
data1 = data[-1,]
n = length(data)
name_to_find = data$X3
find_from = data$X6
}
View(data1)
data1 = data[-1,]
n = length(data1)
name_to_find = data1$X3
find_from = data1$X6
View(data1)
data1 = data[-1,]
n = length(data1)
name_to_find = data.frame(data1$X3)
find_from = data.frame(data1$X6)
View(name_to_find)
View(find_from)
for(i in 1:n){
name = name_to_find[i,1]
for(j in 1:n){
if (name %in% find_from[j,1]){
name_to_find[i,2] = find_from[j,1]
}
}
}
View(name_to_find)
data1 = data[-1,]
n = length(data1)
name_to_find = data.frame(data1$X3)
find_from = data.frame(data1$X6)
for(i in 1:n){
name = name_to_find[i,1]
for(j in 1:n){
if (name %in% find_from[j,1]){
name_to_find[i,2] = find_from[j,1]
}
}
}
i = 1
name = name_to_find[i,1]
name
j = 1
find_from[j,1]
name %in% find_from[j,1]
j = 2
find_from[j,1]
i = 33
name = name_to_find[i,1]
name
j = 82
find_from[j,1]
name %in% find_from[j,1]
name
gsub("[(.*)]", "", name)
find = find_from[j,1]
find
gsub("[(.*)]", "", find)
name %in% find_from[j,1]
gsub(" ", "", find)
name %in% find_from[j,1]
name
gsub("[(.*)]", "", name)
name
name = gsub("[(.*)]", "", name)
name = gsub(" ", "", name)
name
find
find = gsub("[(.*)]", "", find)
find = gsub(" ", "", find)
find
name %in% find
grep("name", find)
library(xlsx)
Sys.setlocale("LC_CTYPE", "chs")
## 修改此处文件路径
data = read.xlsx("E:/bigdata intern/rent/minyue.xls",sheetName="a",header=F,encoding="UTF-8")
data1 = data[-1,]
n = length(data1)
name_to_find = data.frame(data1$X3)
find_from = data.frame(data1$X6)
for(i in 1:n){
name = name_to_find[i,1]
name = gsub("[(.*)]", "", name)
name = gsub(" ", "", name)
for(j in 1:n){
find = find_from[j,1]
find = gsub("[(.*)]", "", find)
find = gsub(" ", "", find)
if (name %in% find){
name_to_find[i,2] = find_from[j,1]
}
}
}
View(name_to_find)
for(i in 1:n){
name = name_to_find[i,1]
name = gsub("[(.*)]", "", name)
name = gsub(" ", "", name)
for(j in 1:n){
find = find_from[j,1]
find = gsub("[(.*)]", "", find)
find = gsub(" ", "", find)
m = length(name)
if (name == find[1:m]){
name_to_find[i,2] = find_from[j,1]
}
}
}
i=33
j=82
name = name_to_find[i,1]
name = gsub("[(.*)]", "", name)
name = gsub(" ", "", name)
find = find_from[j,1]
find = gsub("[(.*)]", "", find)
find = gsub(" ", "", find)
m = length(name)
name
m
install.packages('rjson')
library('rjson')
result <- fromJSON(file = "C:/wamp64/www/bikes-master/www/styles/velobike.json")
View(result)
result <- fromJSON(file = "C:/wamp64/www/bikes-master/www/styles/velobike.json")
View(result)
View(result)
View(result)
View(result)
result[["sources"]]
result1 = as.data.frame(result)
result <- fromJSON(file = "C:/wamp64/www/bikes-master/www/styles/stations_all.json")
result1 = as.data.frame(result)
View(result1)
head(result1)
head(result1,1)
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
install.packages('forecase)
library(forecast)
install.packages('forecast')
library(forecast)
library(forecast)
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
training = sample(toyota.corolla.df$Id,600)
validation = sample(setdiff(toyota.corolla.df$Id, training),400)
reg = lm(Price~., data = toyota.corolla.df[, -c(1,2,8,11)], subset = training, na.action = na.exclude)
pred_t = predict(reg, na.action=na.pass)
pred_v = predict(reg,nwdata=toyota.corolla.df[validation, -c(1,2,8,11)],
na.action=na.pass)
accuracy(pred_t, toyota.corolla.df[training,]$Price)
accuracy(pred_v, toyota.corolla.df[validation,]$Price)
install.packages('gains')
library(forecast)
library(gains)
toyota.corolla.df = toyota.corolla.df[!is.na(toyota.corolla.df[validation,]$Price)]
toyota.corolla.df = toyota.corolla.df[!is.na(toyota.corolla.df[validation,]$Price),]
reg = lm(Price~., data = toyota.corolla.df[, -c(1,2,8,11)], subset = training)
pred_v = predict(reg, newdata = toyota.corolla.df[, -c(1,2,8,11)])
gain = gains(toyota.corolla.df[validation,]$Price[!is.na(pred_v)], pred_v[!is.na(pred_v)])
reg = lm(Price~., data = toyota.corolla.df[, -c(1,2,8,11)], subset = training)
pred_v = predict(reg, newdata = toyota.corolla.df[, -c(1,2,8,11)])
gain = gains(toyota.corolla.df[validation,]$Price[!is.na(pred_v)], pred_v[!is.na(pred_v)])
reg = lm(Price~., data = toyota.corolla.df[, -c(1,2,8,11)], subset = training)
pred_v = predict(reg, newdata = toyota.corolla.df[, -c(1,2,8,11)])
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
toyota.corolla.df = toyota.corolla.df[!is.na(toyota.corolla.df[validation,]$Price),]
training = sample(toyota.corolla.df$Id,600)
validation = sample(setdiff(toyota.corolla.df$Id, training),400)
reg = lm(Price~., data = toyota.corolla.df[, -c(1,2,8,11)], subset = training)
pred_v = predict(reg, newdata = toyota.corolla.df[, -c(1,2,8,11)])
gain = gains(toyota.corolla.df[validation,]$Price[!is.na(pred_v)], pred_v[!is.na(pred_v)])
toyota.corolla.df = toyota.corolla.df[!is.na(toyota.corolla.df[validation,]$Price),]
training = sample(toyota.corolla.df$Id,600)
validation = sample(setdiff(toyota.corolla.df$Id, training),400)
reg = lm(Price~., data = toyota.corolla.df[, -c(1,2,8,11)], subset = training)
pred_v = predict(reg, newdata = toyota.corolla.df[validation, -c(1,2,8,11)])
reg = lm(Price~., data = toyota.corolla.df[, -c(1,2,8,11)], subset = training)
pred_v = predict(reg, newdata = toyota.corolla.df[validation, -c(1,2,8,11)])
gain = gains(toyota.corolla.df[validation,]$Price[!is.na(pred_v)], pred_v[!is.na(pred_v)])
options(scipen=999) # avoid scientific notation # we will compute the gain relative to price
price <- toyota.corolla.df[validation,]$Price[!is.na(toyota.corolla.df[validation,]$Price)]
plot(c(0,gain$cume.pct.of.total*sum(price))~c(0,gain$cume.obs), xlab="# cases", ylab="Cumulative Price", main="Lift Chart", type="l")
# baseline
lines(c(0,sum(price))~c(0,dim(toyota.corolla.df[validation,])[1]), col="gray", lty=2)
# Decile-wise lift chart
barplot(gain$mean.resp/mean(price), names.arg = gain$depth, xlab = "Percentile", ylab = "Mean Response", main = "Decile-wise lift chart")
owner.df <- read.csv("ownerExample.csv")
## cutoff = 0.5 >
confusionMatrix(ifelse(owner.df$Probability>0.5, 'owner', 'nonowner'), owner.df$Class)
install.packages('caret')
library(caret)
owner.df <- read.csv("ownerExample.csv")
## cutoff = 0.5 >
confusionMatrix(ifelse(owner.df$Probability>0.5, 'owner', 'nonowner'), owner.df$Class)
insertClassMethods('e1071')
install.packages('e1071')
library(caret)
library(e1071)
owner.df <- read.csv("ownerExample.csv")
## cutoff = 0.5 >
confusionMatrix(ifelse(owner.df$Probability>0.5, 'owner', 'nonowner'), owner.df$Class)
confusionMatrix(ifelse(owner.df$Probability>0.25, 'owner', 'nonowner'), owner.df$Class)
library(neuralnet)
library(caret) #need this for the preProcess() function
library(forecast) #for the accuracy() function, if you wish to use it...
library(DiscriMiner) #for discriminant analysis
library(gains)
install.packages('stringi')
library(caret) #need this for the preProcess() function
install.packages("stringi",type="mac.binary")
install.packages("stringi",type="win.binary")
library(caret) #need this for the preProcess() function
install.packages("stringi", repos="http://cran.rstudio.com/", dependencies=TRUE)
install.packages('caret')
library(caret) #need this for the preProcess() function
update.packages()
install.packages("neuralnet")
install.packages("DiscriMiner")
install.packages("gains")
library(neuralnet)
library(caret) #need this for the preProcess() function
install.packages("stringi",type="win.binary")
0.258+0.219-0.11
0.258^2+0.219^2-2*0.055
0,633-0.453
.633-.453
0.18/0.004525
0.18/0.004525^0.5
(.633+.453-1)/0.004525^0.5
(.633+.453-1)/( 0.258^2+0.219^2+2*0.055
)^0.5
1300*10+24000
208/112
235/119
235/120
240/121
average(15,13,2,9,0,9,0,1,0,3,0,3,6))
average(15,13,2,9,0,9,0,1,0,3,0,3,6)
mean(15,13,2,9,0,9,0,1,0,3,0,3,6)
mean(c(15,13,2,9,0,9,0,1,0,3,0,3,6))
mean(c(15,13,2,9,0,9,0,1,0,3,0,3,6))
setwd("E:/MIT4/6.439/pset1")
df_gamma = read.csv('data/gamma-ray.csv', stringsAsFactors=F)
View(df_gamma)
View(df_gamma)
